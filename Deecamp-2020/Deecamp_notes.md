<!--
 * @Author: Shuai Wang
 * @Github: https://github.com/wsustcid
 * @Version: 1.0.0
 * @Date: 2020-06-06 08:28:50
 * @LastEditTime: 2020-07-12 17:31:26
 * @Description:  
--> 
# Deecamp
王咏刚开营演讲：
今年是最困难的一年，但也许会像历史上的1986年: 困难的一年，也是改变世界的一年
Geoffrey Hinton + Yann Le Cun

## 0606: 李开复 AI赋能时代的创业
#### 中国AI如何弯道超车
1. 2025 年中国 TOP1 论文数量将与美国相当
2. 在一个新的问题上，数据带来的性能提升远比算法更为重要
3. 无人驾驶： 新基建赋能和加持，就能在技术不成熟的情况下率先上路，上路之后就能采集更多数据，实现滚动优化；
4. 无人驾驶领域，目前中美技术能力还是1:9，差距较大；视觉领域中国已经超过美国（应用角度，因为数据多）
<img src=./assets/3.png width=500>

#### AI从“发明期”进入“应用期”
1. 今天的人工智能正在从科研转向应用的时代；人工智能已从少数精英发明期进入遍地开发应用期
2. 深度学习应用场景太广泛，以后很难再有如此强大的发明；现在的新技术如强化学习，迁移学习，GAN,Transformer等都要弱于深度学习，场景较窄，都是在深度学习基础上发展起来的；
3. 但现在AI的渗透率还比较低:4%；今天的AI+仅相当于互联网黄页时代或相当于没有电网的电力时代；(还没有深度融合)
4. 现在不缺AI科学家，缺AI产业家，如何将AI应用到传统行业，如何用AI赚钱；
5. 未来AI将成为重要的基础设施:2025年AI将无处不在，大多数工程师都将能开发AI；AI不再创造独角兽，而是赋能各个传统行业
6. 智能仓储，智能制造，智慧农业，自动驾驶，机器人；(这些是明确已经被AI赋能的产业)
7. 驭势主要做接驳车；Momenta 是第一家无人驾驶独角兽，下一步希望量产自动驾驶： MPilot；

<img src=./assets/4.png width=500>

#### AI赋能时代的创业特点
科技巨头成功经验分析：
1. 拥有独占性技术
2. 有成熟的产品销售团队
3. 领导人或合伙人有商业背景

科学家往往很不愿意承认自己不具备把技术商业化的洞察与能力，因为：
1. 追求新； (新不一定有价值)
2. 学术严谨; (但效率速度才是关键)
3. 慢工出细活；(快速迭代才能在市场中生存）

以上科学家的三点恰好与企业家的所有所必须的创业特质所违背！！因此科学家不要考虑商业应用，那是企业家的事情，你试图考虑这个问题，你会完败，那是人家的专业；
1. 中美科研成果转化率差距巨大：中国5%， 美国50%
2. 但AI壁垒不会太大，某个技术被发明，无论是否开源，都会很快被其他公司学习使用，所以即使你有一批博士，也不代表你能建立技术壁垒；
3. AI虽然重要，但内容和服务才是核心;
4. AI不需要高大上，需要接地气，比如真实的机器人教师，绝对没人买，远不如虚拟教师；

<img src=./assets/5.png width=500>
<img src=./assets/6.png width=500>
#### 给AI未来人才的建议
1. 创业
2. 加入传统公司：金融 （科技公司用AI已经天经地义）
3. 加入AI赋能公司

AI是下一个互联网，真正的AI公司会越来越少；AI不会成为一个平台，还是一个技术，赋能进入各个平台；
以后大家不会特别的提AI,就像前几年的大数据一样，已经融入了各个领域


Waymo: 无人驾驶L5应该是20年之后的事情；
 - 但他的前提是没有新基建，但新基建有可能加速
 - 但单点切入，滚雪球，先在一些领域得到应用：高速公路，接驳车，自动泊车，仓库；（先有了数据就可以滚动优化）；点对点难 是不是可以做 标准路线的公交车，机场酒店等；
 - Tesla很有可能是做最快做出来的！大胆创新，不断的快速迭代；

下一个风口：
- 技术+商业的结合；单独的技术不太可能成为风口，别人太容易学习；
- 下一步自然语言还是最有可能；

工业领域的问题：
1. 缺数据
2. 训练也不是很容易，出的问题少，有效数据少
3. 非标准化，每个问题出现的场景完全不同；

新创小企业如何不被大企业吃掉：
1. 大公司想要做一个项目，如果你不能证明能挣很多钱，公司不会给你钱让你做，如 他在新领域投入1000万，你这1000万带来的收益能超越我在我的传统领域投入1000万带来的收益高吗?
2. 苦逼，然后低调；大公司才不会看上



## 0606: 张亚勤 New Wave of Digital Transformation
#### Digitalization 3.0 : New wave of digitalization
1. 物理世界的数字化：车、路等等，大量的传感器，都是数字化： 物理的路变成了数字的路
2. 生物世界的数字化：基因、大脑；
3. IT界的发展一直被几个定律所引领：香农三大理论；摩尔定律；冯诺依曼计算机架构；这几大定律都已经逼近极限
4. 人：以较低能耗低完成高效的计算

张亚勤两小时自动驾驶报告（后期搜索）
1. 自动驾驶是接来下的10年对人类来讲是最复杂的问题
2. L5 涉及大脑的三个层次的模型：很多需要只有人类才有的功能才能实现：情感等；开车时牵涉到大脑的每个区域：学的时候具有可解释，但实际学会后，开的时候不涉及思考，下意识的行为，肌肉记忆；但到一个新的路况你又有了解释的能力； 开车并不需要很高的智商，博士生并不一定没上过学的开车开得好；自动驾驶的问题是可以分解的，是可以最终被解决的；
3. L4 五年左右可能会出现；

4. 第四次工业革命

自动驾驶互联网和工业界如何结合：
1. 自动驾驶行业三种组成：汽车制造商（造车：有很深的行业壁垒）；出行公司(有数据有用户)；科技公司(有技术); OEM: 博世(40万员工):真正的技术在OEM

#### 2nd aspect of digital information: ABC Particularly AI
#### New architectural & infrastructural Revolution




## 0607-吴恩达 Full Cycle Machine Learning
### Introduction
The Full Cycle Machine Learning is designed for ML practitioners (Data Scientists, MLEs, Data Engineers, Data Analysts), students of ML/AI as well as data software engineers with some background in ML/AI . This course bridges the gap between being able to develop a ML algorithm/model and being able to develop and deploy a robust ML system to production.

A lot of AI work focuses on building the model---such as the neural network needed to generate a specific X-->Y mapping. But to build practical production systems, many additional steps are needing, ranging from scoping the project, to deciding on the data collection methodology, to making sure the data is high quality, to strategies for model iteration, to practical deployment and monitoring.

#### Contents
问题1: 医学影响检测很多疾病已经实现了专业医生的水平，但为何现在还没有在医院大规模部署呢？
6 Min discuss:
1. 伦理道德，谁负责
2. 医院不信任，不接受；且无法增强医生的经验
3. ...

ML model VS. ML system
1. ML model : X -> y
2. ML system is more large and includes it.

Answer:
1. Many ML project suffer from a Poc (Proof of cconcept) to Prodection gap!
2. small data (数据样本均匀分布时模型工作效果最佳，不均衡时无法对少量类别的数据进行学习和推理)
    - Data augumentation
    - Data synthesis
    - Transfor Learning
3. Robustness & Generalization: A model that works according to a published paper often does not work in a production setting!
   - domain adaptaion; online learning; Incremental learning

4. What big companies do:  (Full-cycle Machine Learning)
   1. Monotor ML system after deployment
   2. Alarms go off when the test set distribution is different
   3. Send in team of engineers to fix things. (Human in the LOOP!!)

ML as a sytemmatic engineering discipline
 - Data editing and data versioning tools
 - Building ML is more like debugging than development
 - Maintenance of ML systems
 - Boundary conditions and formal verification?


## 0613: 张潼-神经网络模型设计和理论研究简介
当今深度学习的发展是以大数据和大计算力为基础的。这个模式在现阶段起到如下作用：设计更深更复杂的模型来提升效果，大模型预训练技术和表示学习取得广泛应用，自动化模型设计成为可能。虽然基于这个模式的深度学习研究有很多的成功案例，但是已经遇到了一系列技术瓶颈。为了进一步的技术突破，我们在现阶段需要建立更加完整的理论体系来指导今后研究。

### 人工设计模型和预训练大模型简介
线性模型-> 非线性模型(浅层网络) -> From Shallow to Deep
- 人脑被激活的区域也是逐步从浅层到深层的
- More effecient representation  of some complex functions (对于浅层网络来说，表示一些函数所需要的神经元数量相对于深层网络来说是需要指数级增长的)
- 正常来讲，你网络加深的时候，网络也要加宽
- 如何加深：ResNet
- 人工设计：适用不同数据的网络局部几何结构（CNN图像，RNN文本，Transformer NLP; GNN）
- how to model long range iteractions: Attention!
<img src=./assets/attention.png width=500>


### 针对特定任务和硬件的自动化模型设计简介
**Deploy Deep laerning Models in Devices**:
为了追求性能 -> 收集更多的数据 -> 构建更大的模型 ； 在算力允许的情况下，总是模型越大，参数越多，效果越好
但实际是 需要不同大小和算力的模型适用不同硬件设备 (无人驾驶车辆需要消耗较多的功耗在传感器设备上)
 - 不同硬件对算子的支持也是不同的
 - 但如何设计？人工减少参数是不现实的，费时费力；（成功案例： MobileNet）


NAS:
- use big computing powers to design effective archietectures
- Architectrures can be task specific and handware specific
- Can achieve SOTA on many tasks
- sitll need human design

components of an NAS system
- search space design
  - hwo to search over architectures
  - require a template designed by human
- Search Algorithm design
  - RL
  - Evolutionary Algorithm
  - oneshot with parameter sharing
<img src=./assets/nas.png width=500>
<img src=./assets/enas.png width=500>

Optimal architectures should scale both width and depth simulataneously
address the problem of resource allocation given computational constraint
 - 越深越难优化
 - 越宽越容易优化； 
 - 同时增加可以降低优化难度


 总结：
 - Archieve task specific and hardware speecific SOTA resusts better than human desings
 - Not fully automated, need human involvement
 - require lots of Computeational power
 - active research area with significant potential to imporve

### 神经网络的优化和过参数化理论简介
深度学习现状： 很多成功案例，但缺乏理论指导
- 很多经验 + bags of tricks
- 缺乏理论体系和深入理解，在盲人摸象
- 遇到瓶颈，技术突破有挑战

下阶段：建立理论体系，指导技术方向
- 理解试验现象
- 建立理论模型
- 找出针对问题的最佳方法
- 搭建整体框架


## 6.14 周志华 机器学习的挑战
### 关于深度模型
错误看法：机器学习30年前就有了，现在只是因为有了数据和大的算力才得到了成功；
事实：06年之前只能训练5层的网络，超过5层就会梯度弥散或消失，并不是因为算力和数据。06年hindon 发明了逐层训练才打破了这种局限，慢慢才发展，所以，根本上算法的发展是促使深度神经网络的成功重要原因之一。

**为什么深度会有效？** （目前无统一认识）
- Increase Mdoel complexity -> Increase learning ability
- 变深比增加神经元更有效（变宽），因为加深同时增加了层数(函数嵌套)和神经元个数
- Increase Mdoel complexity -> Increase risk of overfitting; difficulty in training (机器学习最主要的任务就是避免过拟合)
- 由于 我们有了 大数据(防止过拟合) 大算力 和 训练技巧 导致我们可以使用高复杂度的模型了，而 DNN就是一种简单高效的高复杂度模型

**那为何宽不好呢？**
- 刚才那套解释无法回答这个问题；因为：统一逼近定理；单层网络的复杂度也可以无限大

**DNN最重要的作用**
- 表示学习 (从数据中学习特征)
  - 自动学习特征：端到端
    - 好处：联合优化
    - 但不知道里面发生了什么，也有可能一个往左一个往右相互抵消
  - 表示学习的关键： layer-by-layer processing (这就是深度神经网络能做但浅层网络做不到的，其他的貌似浅的都能做)
  - 但机器学习早就有逐层处理了： 决策树；但为什么不好？： boosting 也是类似
    1. 复杂度不够 （离散属性的话，树的深度确定的）
    2. 始终基于原始特征空间，无特征变换
<img src=./assets/why_deep.png width=500>
所以我们之前认为 有了大数据算力才有了深度神经网络的思路是错的！
<img src=./assets/why_deep_1.png width=500>

<img src=./assets/why_deep_drawback.png width=500>
训练之前必须确定深度，但我们还没解决这个问题，怎么知道他需要他深呢？但只有确定了深度才能BP训练；

**从应用角度**
- 在图像视频语音之外的任务，深度神经网络并非最佳选择，他能解决的 主要就是 数据建模任务 （如符号建模，有些属性不是数值）

**挑战**
- 能否用不可微构件构建一个深度学习模型呢？（这样的话就不需要BP训练，能够解决更多的除图像视频之外的任务）
- 深度森林



### 关于监督信息
一般现实任务中，如何得到“上帝判断” 和无成本的 尝试呢？ （造一个能抗20级台风的桥，每造一次有专家告诉你能否抗台风--这种数据/专家 是不存在的！）

弱监督：
- 监督信息不完全 -> 半监督学习，主动学习
- 监督信息不具体 -> 
- 监督信息不精确
结论：弱监督还有大量的工作要做

思考：驾驶策略的学习貌似也是弱监督的(信息不精确)？

### 关于任务环境
传统机器学习任务：主要针对封闭静态环境 
- 数据分布恒定
- 样本类别恒定
- 样本属性恒定
- 评价目标恒定

但开放动态环境中很多任务都是动的
- 训练的时候一种数据分布，预测的时候数据分布已经变了
<img src=./assets/0614_1.png width=500>
<img src=./assets/0614_2.png width=500>
<img src=./assets/0614_3.png width=500>
<img src=./assets/0614_4.png width=500>

我要应对： 我都不知道 我不知道的情况 unknow unknows

开放动态环境下的xxx研究； 基于规则的你只能解决你知道的情况！不能**推理**你不知道的情况
- 增量学习（增加属性，增加类别）


<img src=./assets/0614_5.png width=500>

从已有的数据中推理出新发生的情况

<img src=./assets/0614_6.png width=500>

<img src=./assets/0614_7.png width=500>



## 0620：俞敏洪 AI在教育领域的应用和教育创业启示

### 智能教育发展的几个阶段

第一阶段：某一个教学小环节，点状的AI应用：作业批改，语音测评等

第二阶段：在教学上形成闭环，连成线：AI课，智能教学系统

第三阶段：线上线下与企业内外形成“面”，构成体，比如AI技术在教育OMO，区域教育均衡中的应用；



**新东方主要围绕AI做教育应用**

- 新东方和科大讯飞合作：前者有数据，讯飞有算法和算力；
- 但核心的东西，如云上课平台



人工智能不能完成的事情：（高级需求？）

- 人与人之间的交往
- 人工智能能辅助教育，但肯定不能完全替代人的教育

<img src=./assets/edu_1.PNG width=500>

<img src=./assets/edu_2.PNG width=500>






## 0627-唐文斌 如何做出真价值的AI产品
**什么是有价值的AI产品(客户角度)**
1. AI行业 与互联网行业不同，后者创者需要，前者的需求就在那里
   - 产品价值 = (新体验-旧体验) - 迁移成本
   - 产品价值的体现：成本优化，效率提升，体验增强    AIoT
     - 比如用机械臂做仓储物流：能否三年以内回本 （投入产出比）

<img src=./assets/ai_app.png width=500>
<img src=./assets/ai_app_1.png width=500>

**我们该提供什么样的AI 产品 (厂商视角)**
1. 产品价值 = (新体验-旧体验 - 迁移成本)X可复制规模X可行性

2. 自动驾驶的发展路线
  - 低速 -> 高速
  - 运货 -> 运人
  - 封闭场景 -> 开放场景

3. 做一个新问题时，一定要尊敬旧方案，然后带着新思路去改变他。（很多事情不是你想的那么简单）

4. 长尾效应，英文名称Long Tail Effect。“头”（head）和“尾”（tail）是两个统计学名词。正态曲线中间的突起部分叫“头”；两边相对平缓的部分叫“尾”。从人们需求的角度来看，大多数的需求会集中在头部，而这部分我们可以称之为流行，而分布在尾部的需求是个性化的，零散的小量的需求。而这部分差异化的、少量的需求会在需求曲线上面形成一条长长的“尾巴”，而所谓长尾效应就在于它的数量上，将所有非流行的市场累加起来就会形成一个比流行市场还大的市场。

5. 怎么做产品：
   - 垂直化：软硬一体的全栈式解决方案
   - 平台化

6. 旷世的几个产品：
   - 用400多台AGV为天猫超市做了一个仓储解决方案
   - Brain++  (通用人工智能平台) 
   - Face++
   - 洞鉴：赋能感知器与决策器
     - 通过目标检测等视觉算法感知提取到数据之后 形成数据池，怎么用？
       - 搜索
       - 报警
       - 数据挖掘
  - 河图：赋能决策器与执行器
<img src=./assets/hetu.png width=500>

<img src=./assets/Megvii.png width=500>


**AI时代需要什么样的人才**
1. 懂技术，懂行业，才能 技术前沿与行业专家相向而行
   - 学习技术，理解行业，把握需求，做出创新(在技术可行性和用户需求之间创造结合点)


## 0628-张宏江 人工智能的发展和投资思考

**ML学术研究现状**
1. 第一代人工智能：知识驱动的符号模型
2. 第三代人工智能： 可信，可靠，安全，高性能  -> 知识驱动+数据驱动 (思考：如何将人类已有知识交给NN,标签是一种形式，如何结合模型？建模是人类的知识的结晶)
   - 新能力，安全性，抗攻击，高性能，下一代

<img src=./assets/ai_history.png width=500>

<img src=./assets/ai_history_1.png width=500>

3. AI的发展是为人类服务的：新三定律
   - AI 需要保护人的隐私 (Federated Learning)
   - AI 需要保护模型的安全
   - AI 需要人类伙伴的理解 (可解释性)

4. 科学发展的四范式
<img src=./assets/scientific.png width=500>

5. 数据的局限性（你如何找到所有相关的数据？光靠视觉或激光雷达的数据够吗？）

<img src=./assets/data.png width=500>

6. Next Decade of AI (or Deep learning) - 这个还是看得比较近
<img src=./assets/ai_future.png width=500>

7. The causal Science Revolution: （更远的思路）
   From data to policies, to expalnations, mechanisms, generalizations ,credit and blame, fairness, creativity, adn free wil.

8. hierarchy
<img src=./assets/hierarchy.png width=500>

9. The decision-making side of machine learning will be a focus in the future.
  - sequences of decisions

<img src=./assets/ai_history_2.png width=500>

**AI的应用与未来**
<img src=./assets/ai_app_2.png width=500>

<img src=./assets/ai_ability.png width=500>


## 我的一些思考：
1. 尽量不要试图去预测未来的或即将要火的研究方向：(做科研的角度)
   - 你预测对了，大佬们早就预测到了，并且已经开始写了，等你做出来，大量的已经发表了
   - 你预测错了，又瞎折腾了一波，纯粹浪费时间
2. 踏踏实实做自己的层次的研究，不一定最新，不一定最先进，只要有自己的思考，自己的工作量就是一个比较好的工作


## 0704: 补看！！！


## 0705: 徐辉-技术产品与商业落地的AI+双轮驱动

### 创新奇智 AI2.0 双轮驱动实践
1. 蒸汽机(1760-1830) -> 电气化(1870-1914) -> 信息通信技术(1950-2015) -> AI技术(2016-)
2. AI1.0: 博士+论文； AI2.0: 商业价值+结果; 产品 -> 解决方案 -> 平台
3. 制造，金融，零售 是AI 赛道中天花板最高、落地最快的企业

## 0711: 联合国项目介绍

## 0712: 计算机视觉：过去、现在和未来 -田奇 (华为诺亚方舟计算机视觉首席科学家)
### 概述
**计算机视觉为什么很难：**
 - 几何信息对视觉很重要
 - 人类视觉存在 "视错觉" 现象
 - 人类习惯想象与联想（卡通，漫画等）：人眼很容易理解表情
 - 人眼具有三维感知能力

**计算机视觉的挑战**
 - 语义鸿沟：底层视觉特征(pixel value) 和高层语义概念之间的关系
 - 缺乏常识：计算机不会犯小错误，会犯大错误; 其表现完全依赖于训练数据
 - 人类具有3D感知能力，计算机没有：很多场景下需要理解 尺寸、深度等概念

### 发展例程
<img src=./assets/vision_1.png width=500>
<img src=./assets/vision_2.png width=500>
<img src=./assets/vision_3.png width=500>
<img src=./assets/vision_4.png width=500>
<img src=./assets/vision_5.png width=500>
<img src=./assets/vision_6.png width=500>

之后进入深度学习时代...

<img src=./assets/vision_7.png width=500>
<img src=./assets/vision_8.png width=500>


<img src=./assets/vision_9.png width=500>

### 无人驾驶介绍
<img src=./assets/ad_1.png width=500>
<img src=./assets/ad_2.png width=500>
<img src=./assets/ad_3.png width=500>

### 华为视觉
<img src=./assets/hw_1.png width=500>